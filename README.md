# Columbia_Capstone-KPMG

## Project Organization

```
Columbia_Capstone-KPMG/
â”‚â”€â”€ configs/                 
â”‚   â””â”€â”€ ingest_parse.yaml       # Config files (parameters for pipelines)
â”‚
â”‚â”€â”€ data/                      
â”‚   â”œâ”€â”€ raw/                    # Raw input documents (NEVER commit to git)
â”‚   â”œâ”€â”€ processed/              # Outputs generated by parsing/processing
â”‚
â”‚â”€â”€ docker/                      
â”‚   â”œâ”€â”€ .env.example            # Template for env variables (Neo4j credentials and configs)
â”‚   â”œâ”€â”€ docker-compose.yml      # Compose file to spin up Neo4j container
â”‚
â”‚â”€â”€ docs/                       # Notes, research findings, design docs
â”‚
â”‚â”€â”€ scripts/                    # CLI entry scripts (team runs these)
â”‚   â””â”€â”€ do_asterisk_chunking.py
â”‚   â””â”€â”€ do_fix_size_chunking.py
â”‚   â””â”€â”€ do_semantic_chunking.py
â”‚   â”œâ”€â”€ doc_converter.py
â”‚   â””â”€â”€ ingest_graph.py
â”‚   â””â”€â”€ ingestion_parse.py
â”‚   â””â”€â”€ reset_graph.py
â”‚   â””â”€â”€ test_neo4j.py
â”‚
â”‚â”€â”€ src/                        # Core source code (modularized)
â”‚   â”œâ”€â”€ doc_2_docx/             # Conversion logic (.doc â†’ .docx; Windows-dependent)
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”‚
â”‚   â”œâ”€â”€ healthcare_rag_llm/     # Main package
â”‚   â”‚   â”œâ”€â”€ doc_parsing/        # Parsing PDF/Docx (tables, watermarks, images)
â”‚   â”‚   â”‚   â””â”€â”€ ...
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ chunking/           # Text splitting strategies
â”‚   â”‚   â”‚   â””â”€â”€ ...
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ embedding/          # Embedding models
â”‚   â”‚   â”‚   â””â”€â”€ ...
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ graph_builder/      # Knowledge Graph builder (refer to README.md for usage note)
â”‚   â”‚   â”‚   â””â”€â”€ ...
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ pipelines/          # Orchestrated workflows (end-to-end)
â”‚   â”‚   â”‚   â””â”€â”€ ...
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ utils/              # Helper functions (I/O, logging, common tools)
â”‚   â”‚   â”‚   â””â”€â”€ ...
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ ...                 # Placeholder for future modules
â”‚   â”‚
â”‚   â””â”€â”€ __init__.py             # Makes src a Python package
â”‚
â”‚â”€â”€ .gitignore                  # Ignores data/, .venv/, logs, etc.
â”‚â”€â”€ pyproject.toml              # Dependency config
â”‚â”€â”€ README.md                   # (this file)
```

## Data Handling

* Put **all raw Medicaid PDFs/Docs** under:

  * **macOS/Linux**:

    ```
    data/raw/Childrens Evolution of Care/
    ```
  * **Windows**:

    ```
    data\raw\Childrens Evolution of Care\
    ```

* Parsed outputs go to:

  * **macOS/Linux**:

    ```
    data/processed/
    ```
  * **Windows**:

    ```
    data\processed\
    ```

* **DO NOT** commit files under `data/` (git will ignore them).
* If you need to share data: use Google Drive/SharePoint.

## System Requirements

### Python Version
- **Required**: Python 3.9 - 3.12
- **Recommended**: Python 3.11
- **Not supported**: Python 3.13+ (PyTorch compatibility)

### Hardware

#### GPU (Highly Recommended for Performance)
- **Supported**: NVIDIA GPUs (GTX 10 series and newer)
  - Examples: RTX 4090, RTX 3080, RTX 2070, GTX 1660
- **Performance**: 10-20x faster than CPU
- **Unsupported GPUs**: Automatically fall back to CPU

#### CPU Only (Works but Slower)
- Any modern multi-core processor
- 8GB+ RAM recommended
- Expect longer processing times

**Performance Comparison**:
- GPU (RTX 2070): ~35 seconds for 5000 chunks
- CPU (Ryzen 7): ~250-500 seconds for 5000 chunks

ğŸ“– **See [INSTALLATION.md](INSTALLATION.md) for detailed requirements and setup instructions.**

## Git Workflow (Team Rules)

1. **Create a branch for each feature/task**

   ```
   git checkout -b feature/<short-description>
   ```

   Examples:

   * `feature/update-doc-parsing`
   * `bugfix/ocr-path`

2. **Commit frequently, but small logical chunks**

   ```
   git add <files>
   git commit -m "Clear message: what & why"
   ```

3. **Sync with main before push**

   ```
   git checkout main
   git pull origin main
   git checkout feature/your-branch
   git merge main
   ```

4. **Push your branch**

   ```
   git push origin feature/your-branch
   ```

5. **Open a Pull Request (PR) on GitHub**

   * Always make a PR into `main`
   * Request at least 1 teammate as reviewer
   * Merge only after review

6. **Delete branch after merge**

   * On GitHub â†’ â€œDelete branchâ€
   * Locally:

     ```
     git branch -d feature/your-branch
     ```

## Quickstart

1. Clone repo & create virtual environment:

* **macOS/Linux**

  ```bash
  git clone git@github.com:xiaojiangwu12338/Columbia_Capstone-KPMG.git
  cd Columbia_Capstone-KPMG
  python3 -m venv .venv
  source .venv/bin/activate
  ```

* **Windows**

  ```powershell
  git clone git@github.com:xiaojiangwu12338/Columbia_Capstone-KPMG.git
  cd Columbia_Capstone-KPMG
  python -m venv .venv
  .\.venv\Scripts\activate
  ```

2. Install PyTorch (GPU support recommended):

  ```bash
  # Universal installation (works on all systems)
  pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121

  # This automatically uses GPU if available, CPU otherwise
  ```

3. Install other dependencies:

  ```bash
  pip install -e .

  # Download NLTK data (required for semantic chunking)
  python -c "import nltk; nltk.download('punkt'); nltk.download('punkt_tab')"
  ```

4. Install system dependencies:

* **macOS**

  ```bash
  brew install tesseract libreoffice
  ```

* **Linux**

  ```bash
  sudo apt-get install tesseract-ocr libreoffice
  ```

* **Windows**

  * [Tesseract OCR](https://github.com/UB-Mannheim/tesseract/wiki)
  * Microsoft Word (via COM) **or** LibreOffice

5. Verify installation:

  ```bash
  python -c "import torch; print(f'Device: {\"GPU - \" + torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU\"}')"
  ```

6. Put sample documents under `data/raw/...`

7. Sample run:

* **macOS/Linux**

  ```bash
  python scripts/ingestion_parse.py --config configs/ingest_parse.yaml
  ```

* **Windows**

  ```powershell
  python scripts\ingestion_parse.py --config configs\ingest_parse.yaml
  ```
